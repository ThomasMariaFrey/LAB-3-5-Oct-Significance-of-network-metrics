---
title: "CSN_Lab3"
author: "Marius"
output: html_document
date: "2023-10-17"
---


```  {r}
# Load required libraries
library(xtable)
library(data.table)
library(igraph)

```


```  {r}
# Define the list of languages
languages <- c("Arabic", "Basque", "Catalan", "Chinese", "Czech", 
               "English", "Greek", "Hungarian", "Italian", "Turkish")

```

Check if in any language contains NA as string
``` {r}
# Set directory
#setwd("~/Desktop/University/CSN-MIRI Complex and Social Networks/Lab/LAB-3-5-Oct-Significance-of-network-metrics")

setwd("~/GitHub/LAB-3-5-Oct-Significance-of-network-metrics/")

# Loop through each language to check for rows with NA values
for (lang in languages) {
  file_name <- paste0("data/", lang, "_syntactic_dependency_network.txt")
  
  # Read the data
  data <- fread(file_name, skip = 1, header = FALSE, quote = "")
  
  # Print rows with NA values
  if (nrow(data[is.na(V1) | is.na(V2), ]) > 0) {
    cat("Rows with NA values for", lang, ":\n")
    print(data[is.na(V1) | is.na(V2), ])
  } else {
    cat("No rows with NA values found for", lang, "\n")
  }
}

```


Create the table with the graph properties
```  {r}
# Set directory
#setwd("~/Desktop/University/CSN-MIRI Complex and Social Networks/Lab/LAB-3-5-Oct-Significance-of-network-metrics")

setwd("~/GitHub/LAB-3-5-Oct-Significance-of-network-metrics/")

# Create an empty list to store the graph objects
data_list <- list()

# Create an empty dataframe to store information about different degree sequences
results <- data.frame(Language = character(0), 
                      N = numeric(0),
                      E = numeric(0),
                      MeanDegree = numeric(0),
                      Density = numeric(0),
                      stringsAsFactors = FALSE)

for (lang in languages) {
  file_name <- paste0("data/", lang, "_syntactic_dependency_network.txt")
  
  # Read the entire file into a data.table
  edges <- fread(file_name, skip = 1, header = FALSE, quote = "", na.strings = "nastring")
  
  # Create an igraph object from the edge list
  graph_obj <- graph_from_data_frame(edges, directed = TRUE)
  
  # Store the graph object
  data_list[[lang]] <- graph_obj
  
  # Get network metrics
  num_vertices <- vcount(graph_obj)
  num_edges <- ecount(graph_obj)
  mean_degree <- 2 * num_edges / num_vertices
  network_density <- 2 * num_edges / (num_vertices * (num_vertices - 1))
  
  # Append to results dataframe
  results <- rbind(results, data.frame(Language = lang, 
                                       N = num_vertices,
                                       E = num_edges,
                                       MeanDegree = mean_degree,
                                       Density = network_density))
}


```
Calculate mean local clustering coefficients
``` {r}
# Create an empty dataframe to store the mean local clustering coefficients
clustering_results <- data.frame(
  Language = character(0),
  RealNetworkClustering = numeric(0),
  stringsAsFactors = FALSE
)

for (lang in languages) {
  # Compute the local clustering coefficient for each node in the real network
  real_network <- data_list[[lang]]
  # if degree(node) < 2, function returns NaN. It need to be replaced with 0
  real_clustering_values <- transitivity(real_network, type = "local")
  
  # Compute the mean of the local clustering coefficients, excluding nodes with a degree less than 2
  # -> essentially excluding loops and multiedges
  real_clustering_values[is.na(real_clustering_values)] <- 0
  
  real_clustering <- mean(real_clustering_values, na.rm = FALSE)
  
  # Append to clustering_results dataframe
  clustering_results <- rbind(clustering_results, data.frame(
    Language = lang,
    RealNetworkClustering = real_clustering
  ))
}

write.csv(clustering_results, "clustering_results.csv")
```

-- ER graphs --

Method 1: Monte Carlo
Computation of correlation coefficients of ER graphs
``` {r}
# -- create ER graphs --
# Define a function to compute Erdös-Rényi (ER) models for the real networks
compute_ERmodels <- function(results, num_ergraphs) {
  
  list_er_graphs <- list()
  
  for (x in 1:nrow(results)) {
    
    # Get the number of nodes and edges from the results dataframe
    N = as.numeric(results$N[x])
    E = as.numeric(results$E[x])
    
    graphs_for_lang <- list()
    
    # Generate num_ergraphs ER graphs for the current language
    for (it in 1:num_ergraphs) {
      
      # Generate an ER graph with N nodes and E edges
      graph = erdos.renyi.game(N, E, type = "gnm")
      
      # Append the generated graph to the list
      graphs_for_lang[[it]] <- graph
    }
    
    # Append the list of generated graphs for the current language to the main list
    list_er_graphs[[as.character(results$Language[x])]] <- graphs_for_lang
  }
  
  return(list_er_graphs)
}

# Number of ER models to generate for each language
# -> Monte Carlo procedure
num_ergraphs = 22

# Call the function to generate the ER models
list_er_graphs <- compute_ERmodels(results, num_ergraphs)


# -- compute clustering coefficients --
# Create an empty list to store clustering coefficient values for the ER graphs
er_clustering_results <- list()

for (lang in languages) {
  
  # Get the ER graphs for the current language.
  er_graphs <- list_er_graphs[[lang]]
  
  # Create a vector to store clustering coefficient values
  clustering_values <- numeric(num_ergraphs)
  
  for (i in 1:num_ergraphs) {
    
    # Get the current ER graph
    graph <- er_graphs[[i]]
    
    # Compute the local clustering coefficient for each node in the graph
    clustering <- transitivity(graph, type = "local", vids = V(graph)[degree(graph) >= 2])
    
    # Store the mean clustering coefficient value
    clustering_values[i] <- mean(clustering, na.rm = TRUE)
  }
  
  # Store the clustering coefficient values for the current language in the main list
  er_clustering_results[[lang]] <- clustering_values
}
```

Calculate p-values
``` {r}

p_values <- numeric(length(languages))
names(p_values) <- languages

for (lang in languages) {
  
  # Get the real network's clustering coefficient for the current language
  real_clustering <- clustering_results[clustering_results$Language == lang,]$RealNetworkClustering
  
  # Get the ER graphs' clustering coefficient values for the current language
  er_clusterings <- er_clustering_results[[lang]]
  
  # Compute the p-value for the current language
  p_values[lang] <- sum(er_clusterings >= real_clustering) / num_ergraphs
}

# Print the computed p-values.
print(p_values)
```
Method 2: Analytical
Define functions
``` {r}
# calculate the expected clustering coefficient for an ER graph
expected_clustering <- function(p) {
  return(p)
}

# calculate the variance of the clustering coefficient for an ER graph
variance_clustering <- function(N, p) {
  return(p * (1 - p) / N + p * (1 - 3 * p + p^2) / N^2)
}

# calculate the Z-score
z_score <- function(C, C_ER, variance_C_ER) {
  return((C - C_ER) / sqrt(variance_C_ER))
}

# calculate the p-value based on the Z-score
# Assuming a two-tailed test
p_value_analytical <- function(Z) {
  return(2 * (1 - pnorm(abs(Z))))
}
```

``` {r}
# Create a vector to store analytical p-values for each language
p_values_analytical <- numeric(length(languages))
names(p_values_analytical) <- languages

# Loop over each language to compute the analytical p-values
for (lang in languages) {
  
  # Get the real network's clustering coefficient 
  real_clustering <- clustering_results[clustering_results$Language == lang,]$RealNetworkClustering
  
  # Get the number of nodes and edges from the results dataframe 
  N = results[results$Language == lang,]$N
  E = results[results$Language == lang,]$E
  
  # Calculate the probability p for the ER graph
  p = E / (N * (N - 1) / 2)
  
  # Calculate the expected clustering coefficient for the ER graph
  C_ER = expected_clustering(p)
  
  # Calculate the variance of the clustering coefficient for the ER graph
  variance_C_ER = variance_clustering(N, p)
  
  # Calculate the Z-score.
  Z = z_score(real_clustering, C_ER, variance_C_ER)
  
  # Compute the analytical p-value 
  p_values_analytical[lang] = p_value_analytical(Z)
}

# Print the computed analytical p-values.
print(p_values_analytical)
```


##### -- Switching Model --
Random graphs with the same degree sequence as the real graphs generated by the 
syntactic dependencies of  languages generated by the Switching Model

Set the working directory, load the requested libraries and obtain the source 
code.
```{r}
#Change to your working directoy
#setwd("~/Desktop/University/CSN-MIRI Complex and Social Networks/Lab/LAB-3-5-Oct-Significance-of-network-metrics")

# Load required libraries
library(xtable)
library(data.table)
library(igraph)
```

Set the basic required variables
```{r}
# We had to remove czech because it kept throwing a fatal error
languages <- c("Arabic", "Basque", "Catalan", "Chinese",
               "English", "Greek", "Hungarian", "Italian", "Turkish")
# The number of switching models that are to be created and estimated. This 
# should be at least 20
nSwitch <- 10
# The size of the switch graphs that are estimated.
Estimationpercentage <- 0.05
clusteringResults <- read.csv("clustering_results.csv")
realClusteringCoefficientValues <- clusteringResults$RealNetworkClustering
# Removing the value for chzech
realClusteringCoefficientValues <- realClusteringCoefficientValues[-5]

```

P Value Calculation Function: This function uses the Monte Carlos simulation 
function that is used to compare the clustering coefficent of the switch model
graphs to the clustering coefficent of the original graphs. This is done by 
calculating the proportion of randomized graphs that have a clustering 
coefficent greater or equal thatn the original model.
```{r}
CalculatePValueForSwitching <- function(graph, realClusteringCoefficient){
  # Compute the number of nodes in the graph
  numNodesTotal <- vcount(graph)
  # Initializing the largerclust to 0
  largerClust <- 0
  # Create a switching model multiple times for a given time and graph
  # thereafter calculate the relevant clustering coefficient here
  for (i in seq(1,nSwitch)){
    # Create the graph
    switchingGraph <- createSwitchingGraph(graph)
    # Calculate the clustering coefficient
    switchClusteringCoefficient <- estimateGraphClusteringCoefficient(switchingGraph)
    # If the clustering coefficient of the switch model is larger than the 
    # clustering coefficient of the real graph increment largerClust by one
    if (switchClusteringCoefficient >= realClusteringCoefficient){
      largerClust = largerClust + 1
    } 
  }
  # Return the p value for the switching graph.
  return(largerClust/nSwitch)
}
```

Switching model Function: This function will modify the structure of original 
synthetic dependency networks by "switching" to create a new graph that
preserves the degree distribution of the orignal graph but is otherwise 
randomized. This is done by calculating valid edge switches. Valid means
that it does not create loops or multiple edges. There after the switches are
applied. We then calculate the clustering coefficient by wattz and strogatz.
The switchin model should have no influence on the local clustering coefficient.
```{r}
createSwitchingGraph <-function(graph){
    edgeData = as_edgelist(graph, names = FALSE)
    E = nrow(edgeData)

    # This has to be done to ensure that the larger graphs can be loaded into 
    # memory, setting sparse to false
    adjacendcyMatrix = as_adjacency_matrix(graph, names = FALSE, type = "both", sparse=FALSE)
    
    # Coupon calculation, ensuring that it is larger than 10 for the best value
    minQ <- 10
    Q <- log(E)
    if(minQ > Q){
      Q <- minQ
    }
    # The amount of switches that will be done should be log(E) * E
    switchesAmount <- Q * E 
    
    # We obtain an initial amount of edges for that the nodes shall be switched.
    firstEdgeIndices = sample(1:E, switchesAmount, replace = TRUE)
    secondEdgeIndices = sample(1:E, switchesAmount, replace = TRUE)
    
    # Doing the switchesAmount of switches to permute the real graph into a 
    # switch graph
    for (idx in seq(1, switchesAmount)) {
        firstEdge = edgeData[firstEdgeIndices[idx],]
        secondEdge = edgeData[secondEdgeIndices[idx],]
        
        origFirstEdge = firstEdge
        origSecondEdge = secondEdge
        
        # Make sure that all edges are different and there are no redundant 
        # edges present so that a successfull switch can be made
        if (all(firstEdge != secondEdge) && adjacendcyMatrix[secondEdge[1], firstEdge[2]] == 0 && adjacendcyMatrix[firstEdge[2], secondEdge[1]] == 0 && adjacendcyMatrix[firstEdge[2], secondEdge[1]] == 0 && adjacendcyMatrix[firstEdge[1], secondEdge[2]] == 0 && adjacendcyMatrix[secondEdge[2], firstEdge[1]] == 0) {
          
            
            #Delete the old adjacencies
            adjacendcyMatrix[origFirstEdge[1], origFirstEdge[2]] = 0
            adjacendcyMatrix[origFirstEdge[2], origFirstEdge[1]] = 0
            adjacendcyMatrix[origSecondEdge[1], origSecondEdge[2]] = 0
            adjacendcyMatrix[origSecondEdge[2], origSecondEdge[1]] = 0

            #Switch the first and second edge
            swapped = firstEdge[2]
            firstEdge[2] = secondEdge[2]
            secondEdge[2] = swapped
            edgeData[firstEdgeIndices[idx],] = firstEdge
            edgeData[secondEdgeIndices[idx],] = secondEdge
            
            #Create the new adjacencies
            adjacendcyMatrix[firstEdge[1], firstEdge[2]] = 1
            adjacendcyMatrix[firstEdge[2], firstEdge[1]] = 1
            adjacendcyMatrix[secondEdge[1], secondEdge[2]] = 1
            adjacendcyMatrix[secondEdge[2], secondEdge[1]] = 1
        }
    }
    # Recreate the graph from the edgelist and return it 
    randomizedSwitchGraph<-graph_from_edgelist(edgeData, directed = FALSE)
    return(randomizedSwitchGraph)
}
```

Estimate Graph Clustering Coefficient Function: We estimate the clustering 
coefficent for a subset of nodes and the average this value to obtain an 
estimate of the overall closeness metric.
```{r}
estimateGraphClusteringCoefficient <- function(graph){
  # Counting the amount of nodes to be considered
  nodesAmount <- vcount(graph)
  # Computing the sample size of the graph
  sampleSize = nodesAmount * Estimationpercentage
  # Selecting the nodes to be sampled
  selectedNodes <- sample(V(graph), size = sampleSize)
  # Calculating the clustering coefficient of the selected samples
  localClusteringCoefficients <- transitivity(graph, vids=selectedNodes, type = "local")
  # Replacing all Nan values with 0. Nan values are these with less than two 
  # edges
  localClusteringCoefficients[is.nan(localClusteringCoefficients)] <- 0
  # Calculating the mean local clustering coefficient for return
  averageClusteringCoefficient <- mean(localClusteringCoefficients)
  return(averageClusteringCoefficient)
}
```

Running the switching model
```{r}
# i for selecting the relevant real clustering coefficient values to compare
# against
i <- 1
# Vector for stroring th c values
pvalues <- c()
# The amount of iterations that will be done, should be at least 20 for a real 
# run
print("Amount of iterations: ")
print(nSwitch)
# For all languages except czech because that one causes RStudio to crash
for (lang in languages) {
  # Create the relevant path
  file_name <- paste0("../data/", lang, "_syntactic_dependency_network.txt")
  # Read in the table
  edgeData <- read.table(file_name, skip = 1, header = FALSE, stringsAsFactors = FALSE, quote = "", sep = " ", na.strings = "")
  # Create a basic graph
  graph = graph.data.frame(edgeData)
  # Remove potential multiples and loops in the graph
  graph = simplify(graph,remove.multiple = TRUE,remove.loops = TRUE)
  # Extract the real clustering coefficient value for the current language
  relevantResult <- realClusteringCoefficientValues[i]
  # Use the switching methods to calculate the p value
  pvalue <- CalculatePValueForSwitching(graph,relevantResult)
  # Append to pvalue list
  pvalues <- c(pvalues, pvalue)
  # Safe the calculated values in a txt file
  write(pvalues, file = "pvalues50.txt")
  i <- i+1
}
# Create a df with all pvalues
pvalueswitchdf <- data.frame(Languages = languages, PValues = pvalues)
# Write these values into a csv
write.csv(pvalueswitchdf, file = "switchpvalues.csv", row.names = FALSE)

```


############################## Time testing below ############################## 

Testing the of different orderings of vertices for estimating the p value of distributions 
The relevant orderings are: Original ordering, Random ordering of vertices, Increasing order by degree, decreasing order by degree. They will be tested by speed. This will be done with the Basque language as it is the smallest one

Functions for the time tests
```{r}
timeTestCalculatePValueForSwitching <- function(graph, realClusteringCoefficient){
  # Compute the number of nodes in the graph
  numNodesTotal <- vcount(graph)
  # Initializing the largerclust to 0
  largerClust <- 0
  timings <- numeric()
  # Create a switching model multiple times for a given time and graph
  # thereafter calculate the relevant clustering coefficient here
  start_time_1<-proc.time()
  for (i in seq(1,nSwitch)){
    # Create the graph
    switchingGraph <- createSwitchingGraph(graph)
    # Calculate the clustering coefficient
    switchClusteringCoefficient <- timeTestORIGINALestimateGraphClusteringCoefficient(switchingGraph)
    # If the clustering coefficient of the switch model is larger than the 
    # clustering coefficient of the real graph increment largerClust by one
    if (switchClusteringCoefficient >= realClusteringCoefficient){
      largerClust = largerClust + 1
    } 
  }
  end_time_1<-proc.time()
  elapsed_time <- end_time_1[3] - start_time_1[3]
  timings <- c(timings, elapsed_time)
  
  start_time_2<-proc.time()
    for (i in seq(1,nSwitch)){
    # Create the graph
    switchingGraph <- createSwitchingGraph(graph)
    # Calculate the clustering coefficient
    switchClusteringCoefficient <- timeTestRANDOMestimateGraphClusteringCoefficient(switchingGraph)
    # If the clustering coefficient of the switch model is larger than the 
    # clustering coefficient of the real graph increment largerClust by one
    if (switchClusteringCoefficient >= realClusteringCoefficient){
      largerClust = largerClust + 1
    } 
  }
  end_time_2<-proc.time()
  elapsed_time <- end_time_2[3] - start_time_2[3]
  timings <- c(timings, elapsed_time)
  
    start_time_3<-proc.time()
    for (i in seq(1,nSwitch)){
    # Create the graph
    switchingGraph <- createSwitchingGraph(graph)
    # Calculate the clustering coefficient
    switchClusteringCoefficient <- timeTestASCENDINGestimateGraphClusteringCoefficient(switchingGraph)
    # If the clustering coefficient of the switch model is larger than the 
    # clustering coefficient of the real graph increment largerClust by one
    if (switchClusteringCoefficient >= realClusteringCoefficient){
      largerClust = largerClust + 1
    } 
  }
  end_time_3<-proc.time()
  elapsed_time <- end_time_3[3] - start_time_3[3]
  timings <- c(timings, elapsed_time)
  
      start_time_4<-proc.time()
    for (i in seq(1,nSwitch)){
    # Create the graph
    switchingGraph <- createSwitchingGraph(graph)
    # Calculate the clustering coefficient
    switchClusteringCoefficient <- timeTestDECENDINGestimateGraphClusteringCoefficient(switchingGraph)
    # If the clustering coefficient of the switch model is larger than the 
    # clustering coefficient of the real graph increment largerClust by one
    if (switchClusteringCoefficient >= realClusteringCoefficient){
      largerClust = largerClust + 1
    } 
  }
  end_time_4<-proc.time()
  elapsed_time <- end_time_4[3] - start_time_4[3]
  timings <- c(timings, elapsed_time)
  
  print(timings)
  write.table(timings, file = "timings.txt", row.names = FALSE, col.names = FALSE, quote = FALSE)
  
  # Return the p value for the switching graph.
  return(largerClust/nSwitch)
}
```


Estimation functions for the graph clustering coefficient given different sampleing strategies.
```{r}
timeTestORIGINALestimateGraphClusteringCoefficient <- function(graph){
  # Counting the amount of nodes to be considered
  nodesAmount <- vcount(graph)
  # Computing the sample size of the graph
  sampleSize = nodesAmount * Estimationpercentage
  # Selecting the nodes to be sampled ORIGINALLY
  selectedNodes <- V(graph)[1:sampleSize]
  # Calculating the clustering coefficient of the selected samples
  localClusteringCoefficients <- transitivity(graph, vids=selectedNodes, type = "local")
  # Replacing all Nan values with 0. Nan values are these with less than two 
  # edges
  localClusteringCoefficients[is.nan(localClusteringCoefficients)] <- 0
  # Calculating the mean local clustering coefficient for return
  averageClusteringCoefficient <- mean(localClusteringCoefficients)
  return(averageClusteringCoefficient)
}

timeTestRANDOMestimateGraphClusteringCoefficient <- function(graph){
  # Counting the amount of nodes to be considered
  nodesAmount <- vcount(graph)
  # Computing the sample size of the graph
  sampleSize = nodesAmount * Estimationpercentage
  # Selecting the nodes to be sampled RANDOMLY
  selectedNodes <- sample(V(graph), size = sampleSize)
  # Calculating the clustering coefficient of the selected samples
  localClusteringCoefficients <- transitivity(graph, vids=selectedNodes, type = "local")
  # Replacing all Nan values with 0. Nan values are these with less than two 
  # edges
  localClusteringCoefficients[is.nan(localClusteringCoefficients)] <- 0
  # Calculating the mean local clustering coefficient for return
  averageClusteringCoefficient <- mean(localClusteringCoefficients)
  return(averageClusteringCoefficient)
}

timeTestASCENDINGestimateGraphClusteringCoefficient <- function(graph){
  # Counting the amount of nodes to be considered
  nodesAmount <- vcount(graph)
  # Computing the sample size of the graph
  sampleSize = nodesAmount * Estimationpercentage
  # Selecting the nodes to be sampled ASCENDINGLY
  ordered_nodes <- order(degree(graph))
  selectedNodes <- ordered_nodes[1:sampleSize]
  # Calculating the clustering coefficient of the selected samples
  localClusteringCoefficients <- transitivity(graph, vids=selectedNodes, type = "local")
  # Replacing all Nan values with 0. Nan values are these with less than two 
  # edges
  localClusteringCoefficients[is.nan(localClusteringCoefficients)] <- 0
  # Calculating the mean local clustering coefficient for return
  averageClusteringCoefficient <- mean(localClusteringCoefficients)
  return(averageClusteringCoefficient)
}

timeTestDECENDINGestimateGraphClusteringCoefficient <- function(graph){
  # Counting the amount of nodes to be considered
  nodesAmount <- vcount(graph)
  # Computing the sample size of the graph
  sampleSize = nodesAmount * Estimationpercentage
  # Selecting the nodes to be sampled DECENDINGLY
  ordered_nodes <- order(-degree(graph))
  selectedNodes <- ordered_nodes[1:sampleSize]
  # Calculating the clustering coefficient of the selected samples
  localClusteringCoefficients <- transitivity(graph, vids=selectedNodes, type = "local")
  # Replacing all Nan values with 0. Nan values are these with less than two 
  # edges
  localClusteringCoefficients[is.nan(localClusteringCoefficients)] <- 0
  # Calculating the mean local clustering coefficient for return
  averageClusteringCoefficient <- mean(localClusteringCoefficients)
  return(averageClusteringCoefficient)
}

```

Running the time testing
```{r}
# Create the relevant path
file_name <- paste0("../data/", "Basque", "_syntactic_dependency_network.txt")
# Read in the table
edgeData <- read.table(file_name, skip = 1, header = FALSE, stringsAsFactors = FALSE, quote = "", sep = " ", na.strings = "")
# Create a basic graph
graph = graph.data.frame(edgeData)
# Remove potential multiples and loops in the graph
graph = simplify(graph,remove.multiple = TRUE,remove.loops = TRUE)
# Extract the real clustering coefficient value for the current language
relevantResult <- 0.078
# Use the switching methods to calculate the p value
pvalue <- timeTestCalculatePValueForSwitching(graph,relevantResult)
# Append to pvalue list
pvalues <- c(pvalues, pvalue)
# Safe the calculated values in a txt file
write(pvalues, file = "pvaluesSpeedTest.txt")
```